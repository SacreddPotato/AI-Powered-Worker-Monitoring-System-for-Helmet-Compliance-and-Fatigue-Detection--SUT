<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>FAQ — Technical Details</title>
    <link rel="stylesheet" href="styles.css?v=999" />
    <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />

    <!-- ✅ FORCE COLORS -->
    <style>
      .faq-questions .question {
        background: #14b8a6 !important;
        color: white !important;
      }

      .faq-questions .question:hover {
        background: #0d9488 !important;
      }

      .faq-questions .question.active {
        background: linear-gradient(
          135deg,
          #667eea 0%,
          #764ba2 100%
        ) !important;
      }
    </style>
  </head>
  <body>
    <div id="sidebarOverlay"></div>

    <div class="site">
      <aside id="sidebar" class="sidebar">
        <div class="brand">
          <img src="assets/logo.jpeg" class="logo" alt="Project Logo" />
          <div class="brand-text">
            <div class="univ">Safety Monitoring AI</div>
          </div>
        </div>

        <nav class="side-nav">
          <a href="index.html" class="nav-link">Home</a>
          <a href="about.html" class="nav-link">About the Project</a>
          <a href="helmet.html" class="nav-link">AI Helmet Detection</a>
          <a href="fatigue.html" class="nav-link">Fatigue Detection</a>
          <a href="fatigue-v2.html" class="nav-link">Fatigue Detection V2</a>
          <a href="faq.html" class="nav-link active">FAQ</a>
        </nav>

        <div class="side-footer">Capstone Project • 2024-2025</div>
      </aside>

      <div class="main">
        <header class="topbar">
          <div class="top-left">
            <button id="menuToggle" class="hamburger">☰</button>
            <div class="title">Frequently Asked Questions</div>
          </div>
          <div class="top-right">
            <a href="about.html" class="link primary">Back to Team</a>
          </div>
        </header>

        <main class="content">
          <div class="faq-area">
            <aside class="faq-questions" style="padding: 0">
              <ul
                style="
                  list-style: none;
                  padding: 0;
                  margin: 0;
                  display: flex;
                  flex-direction: column;
                  gap: 0.5rem;
                "
              >
                <li class="question nav-link active" data-answer="ans1">
                  What dataset did you use?
                </li>
                <li class="question nav-link" data-answer="ans2">
                  How does the fatigue logic work?
                </li>
                <li class="question nav-link" data-answer="ans3">
                  Is video data saved?
                </li>
                <li class="question nav-link" data-answer="ans4">
                  Does it work with glasses?
                </li>
                <li class="question nav-link" data-answer="ans5">
                  Hardware Requirements?
                </li>
              </ul>
            </aside>

            <section class="faq-answer card" id="faqAnswer">
              <div id="ans1">
                <h4>What dataset did you use?</h4>
                <p>We used 3 different datasets for the 3 models we have:</p>
                <ul>
                  <li>
                    <strong>Fatigue Detection V1:</strong>
                    We used the
                    <a
                      style="text-decoration: underline"
                      href="https://www.kaggle.com/datasets/minhngt02/uta-rldd"
                      ><strong>UTA-RLDD Fatigue Detection Dataset</strong></a
                    >
                    for this model. (Divided into 2 distinct classes for binary detection)
                  </li>
                  <li>
                    <strong>Fatigue Detection Version 2 (3 States):</strong>
                    We used
                    <a
                      style="text-decoration: underline"
                      href="https://www.kaggle.com/datasets/timmjy/fatigue-detection"
                      ><strong>UTA-RLDD Fatigue Detection Dataset</strong></a
                    >
                    for this model. (Divided into 3 classes to enable detection across 3 states [Active, Non-Vigilant, Fatigued])
                  </li>
                  <li>
                    <strong>Helmet Detection:</strong>
                    We used a readily available <a href="https://www.kaggle.com/datasets/andrewmvd/hard-hat-detection" style="text-decoration: underline;"><strong>Kaggle</strong></a> dataset.
                  </li>
                </ul>
              </div>

              <div id="ans2" class="hidden">
                <h4>How does the fatigue logic work?</h4>
                <p>
                  We use a <strong>Hybrid Approach</strong> to ensure accuracy:
                </p>
                <ul>
                  <li>
                    <strong>Geometric Analysis:</strong> We use Dlib to track 68
                    facial landmarks, calculating the Eye Aspect Ratio (EAR) and
                    Mouth Aspect Ratio (MAR) to detect physical signs like
                    blinking and yawning.
                  </li>
                  <li>
                    <strong>Deep Learning:</strong> Simultaneously, a Swin
                    Transformer model analyzes the visual features of the face
                    to classify the overall state (Alert vs. Fatigued) for V1
                    and for Fatigue V2 (Alert vs. Non-Vigilant vs. Tired).
                  </li>
                </ul>
                <p>
                  The final decision is a weighted average of these two systems.
                </p>
              </div>

              <div id="ans3" class="hidden">
                <h4>Is video data saved?</h4>
                <p>
                  <strong>No.</strong> The system processes video feeds in
                  real-time Random Access Memory (RAM). No video footage is
                  written to the disk or database to ensure worker privacy.
                </p>
                <p>
                  <em
                    >Note: If you use the "Upload Video" feature for testing,
                    the file is temporarily stored for processing and then
                    deleted.</em
                  >
                </p>
              </div>

              <div id="ans4" class="hidden">
                <h4>Does it work with glasses?</h4>
                <p>
                  Yes, but with limitations. The Dlib landmark detector
                  generally works well with transparent glasses. However, dark
                  sunglasses or heavy reflections may block the eye tracking
                  (EAR). In these cases, our Swin Transformer model acts as a
                  backup since it analyzes the entire face context rather than
                  just the eyes.
                </p>
              </div>

              <div id="ans5" class="hidden">
                <h4>Hardware Requirements?</h4>
                <p>
                  The system is designed to be lightweight, but performance
                  varies by hardware:
                </p>
                <ul>
                  <li>
                    <strong>CPU Only:</strong> Works for the Helmet Detection
                    (YOLOv8n) but may run at lower FPS (5-10 FPS).
                  </li>
                  <li>
                    <strong>GPU (Recommended):</strong> For the Fatigue
                    Detection module (Swin Transformer), a CUDA-enabled GPU is
                    recommended to achieve real-time performance (25+ FPS) due
                    to the complexity of the transformer model. However, a CPU
                    will do the job for testing purposes.
                  </li>
                </ul>
              </div>
            </section>
          </div>
        </main>
      </div>
    </div>

    <script src="app.js"></script>
  </body>
</html>
